#!/usr/bin/env -S uv run --script
# /// script
# requires-python = ">=3.11"
# dependencies = [
#   "httpx",
# ]
# ///
"""
git-smart-commit: Analyze unstaged changes, group into logical commits, execute them.

Uses Qwen3-Coder-30B-A3B via Ollama for classification.

Usage:
    git-smart-commit [--repo PATH] [--dry-run] [--model MODEL] [--yes]

Options:
    --repo PATH     Path to git repository (default: current directory)
    --dry-run       Print proposed commits without executing
    --model MODEL   Ollama model to use (default: qwen2.5-coder:32b)
    --yes           Skip confirmation prompt and commit immediately
    --json          Output proposed commits as JSON and exit (implies --dry-run)
    --help          Show this message

Exit codes:
    0   Success
    1   No changes found
    2   Model/Ollama error
    3   Git error
    4   User cancelled
"""

import argparse
import json
import subprocess
import sys
import textwrap
from pathlib import Path

import httpx

# ── Configuration ──────────────────────────────────────────────────────────────

OLLAMA_BASE_URL = "http://localhost:11434"
DEFAULT_MODEL = "qwen3-coder:30b-a3b-q8_0"
OLLAMA_TIMEOUT = 300.0
NUM_CTX = 128000

# ── Git helpers ────────────────────────────────────────────────────────────────

def git(args: list[str], cwd: Path) -> str:
    """Run a git command and return stdout. Raises on non-zero exit."""
    result = subprocess.run(
        ["git"] + args,
        cwd=cwd,
        capture_output=True,
        text=True,
    )
    if result.returncode != 0:
        raise RuntimeError(f"git {' '.join(args)} failed:\n{result.stderr.strip()}")
    return result.stdout


def get_changed_files(repo: Path) -> list[str]:
    """Return list of files with unstaged or staged changes."""
    # Both staged (cached) and unstaged, deduped
    staged = git(["diff", "--cached", "--name-only"], repo).splitlines()
    unstaged = git(["diff", "--name-only"], repo).splitlines()
    untracked = git(["ls-files", "--others", "--exclude-standard"], repo).splitlines()
    seen = set()
    files = []
    for f in staged + unstaged + untracked:
        if f and f not in seen:
            seen.add(f)
            files.append(f)
    return files


DIFF_CHARS_PER_FILE = 6000    # files larger than this get hunk-summarized
DIFF_TOTAL_CHARS   = 120000   # hard cap on total context sent to classifier
HUNK_SUMMARIZE_CTX = 8192     # smaller context for summarization calls (faster)


def split_hunks(diff_text: str) -> list[str]:
    """Split a unified diff into individual hunks (each starting with @@)."""
    lines = diff_text.splitlines(keepends=True)
    hunks: list[str] = []
    header_lines: list[str] = []
    current: list[str] = []

    for line in lines:
        if line.startswith("@@"):
            if current:
                hunks.append("".join(current))
            current = header_lines + [line]
        elif line.startswith(("diff --git", "index ", "--- ", "+++ ")):
            header_lines.append(line)
            if current:
                # flush any open hunk first
                hunks.append("".join(current))
                current = []
        else:
            if current:
                current.append(line)
            # lines before the first @@ go into header_lines
            elif not line.startswith("@@"):
                header_lines.append(line)

    if current:
        hunks.append("".join(current))

    return hunks or [diff_text]   # fallback: treat whole diff as one hunk


PRIOR_HUNK_WINDOW = 3   # how many previous hunk summaries to include as context


def summarize_file_diff(model: str, fname: str, diff_text: str) -> str:
    """Ask the model to summarize each hunk, passing the last 3 summaries as context."""
    hunks = split_hunks(diff_text)
    hunk_summaries: list[str] = []

    for i, hunk in enumerate(hunks, 1):
        hunk_snippet = hunk if len(hunk) <= 4000 else hunk[:4000] + "\n... (hunk truncated)"

        prior_context = ""
        if hunk_summaries:
            window = hunk_summaries[-PRIOR_HUNK_WINDOW:]
            start_idx = i - len(window)
            prior_context = "Previous hunks in this file:\n" + "\n".join(
                f"  Hunk {start_idx + j}: {s}" for j, s in enumerate(window)
            ) + "\n\n"

        prompt = textwrap.dedent(f"""\
            Summarize hunk {i} of {len(hunks)} from '{fname}' in 1-3 plain English sentences.
            Focus on WHAT changed and WHY it matters (if inferable). No jargon, no bullet points.
            Do not mention line numbers. Output only the summary, nothing else.

            {prior_context}Hunk {i}:
            {hunk_snippet}
        """)
        summary = call_ollama(model, prompt, num_ctx=HUNK_SUMMARIZE_CTX)
        hunk_summaries.append(summary.strip())

    return f"[summarized — {len(hunks)} hunk(s)]\n" + "\n".join(
        f"  Hunk {i}: {s}" for i, s in enumerate(hunk_summaries, 1)
    )


def build_diff_summary(repo: Path, model: str) -> str:
    """Return diff context for the classifier.

    Small files: include raw diff.
    Large files: summarize each hunk via a fast model call, then include summaries.
    """
    parts: list[str] = []
    total_chars = 0

    for label, extra_args in [("Staged", ["--cached"]), ("Unstaged", [])]:
        stat = git(["diff"] + extra_args + ["--stat", "--no-color"], repo).strip()
        if not stat:
            continue
        parts.append(f"{label}:\n{stat}\n")

        changed = git(["diff"] + extra_args + ["--name-only"], repo).splitlines()
        for fname in changed:
            file_diff = git(["diff"] + extra_args + ["--no-color", "--", fname], repo)

            if len(file_diff) <= DIFF_CHARS_PER_FILE:
                content = file_diff
            else:
                print(f"  Summarizing large diff: {fname} ({len(file_diff):,} chars)…",
                      file=sys.stderr)
                content = summarize_file_diff(model, fname, file_diff)

            parts.append(content)
            total_chars += len(content)

            if total_chars >= DIFF_TOTAL_CHARS:
                parts.append("\n... (remaining diffs omitted — total size limit reached)")
                break
        else:
            continue
        break   # hit total limit inside inner loop

    untracked = git(["ls-files", "--others", "--exclude-standard"], repo).splitlines()
    if untracked:
        parts.append("Untracked (new files):\n" + "\n".join(f"  {f}" for f in untracked))

    return "\n".join(parts)


# ── Ollama client ──────────────────────────────────────────────────────────────

def call_ollama(model: str, prompt: str, num_ctx: int = NUM_CTX) -> str:
    """Call Ollama chat completions and return the assistant message text."""
    payload = {
        "model": model,
        "messages": [{"role": "user", "content": prompt}],
        "stream": True,
        "keep_alive": "1h",
        "options": {
            "temperature": 0.1,   # low temp for deterministic classification
            "num_ctx": num_ctx,
        },
    }
    # try:
    with httpx.Client(timeout=httpx.Timeout(connect=30.0, read=60.0, write=30.0, pool=5.0)) as client:
        with client.stream("POST", f"{OLLAMA_BASE_URL}/api/chat", json=payload) as response:
            response.raise_for_status()
            chunks = []
            for line in response.iter_lines():
                if not line:
                    continue
                try:
                    data = json.loads(line)
                except json.JSONDecodeError:
                    continue
                content = data.get("message", {}).get("content", "")
                if content:
                    chunks.append(content)
                if data.get("done"):
                    break
            return "".join(chunks)
    #except httpx.ConnectError:
    #    print("Error: Cannot connect to Ollama. Is it running? (ollama serve)", file=sys.stderr)
    #    sys.exit(2)
    #except httpx.HTTPStatusError as e:
    #    try:
    #        body = e.response.read().decode()
    #    except Exception:
    #        body = "(unreadable)"
    #    print(f"Error: Ollama returned {e.response.status_code} for {e.request.url}: {body}", file=sys.stderr)
    #    sys.exit(2)


# ── Classification prompt ──────────────────────────────────────────────────────

SYSTEM_PROMPT = textwrap.dedent("""\
    You are a senior software engineer helping organize messy working-tree changes
    into clean, logical git commits.

    Given a list of changed files and their diffs, your job is to group them into
    one or more commits. Each commit should represent a single logical change
    (e.g. "add feature X", "fix bug in Y", "update dependencies", "refactor Z").

    You do not need to commit every file. Skip junk files (editor backups,
    build artifacts, OS metadata). Instead, collect suggested .gitignore patterns
    for them in the top-level "gitignore" field.

    Rules:
    - Keep related changes together (same feature, same module, same concern)
    - Separate unrelated concerns into different commits
    - Dependency/lockfile changes belong with the commit that caused them
    - Test files belong with the code they test
    - Use conventional commit format:
        subject: type(scope): short description  (under 72 chars)
        body: 4-10 lines, plain text, wrapped at 80 chars, no markdown
      Types: feat, fix, refactor, chore, docs, test, style, build, ci

    Respond ONLY with a JSON object. No prose, no markdown fences. Schema:
    {
      "commits": [
        {
          "subject": "feat(auth): add JWT refresh token support",
          "body": "Implements RFC 7519 refresh tokens with a 30-day expiry.\nAdds /auth/refresh endpoint and updates the token middleware\nto validate refresh tokens separately from access tokens.",
          "files": ["src/auth/refresh.py", "tests/test_refresh.py"]
        },
        {
          "subject": "chore(deps): bump httpx to 0.27",
          "body": "Picks up the connection pool fix from upstream.",
          "files": ["requirements.txt", "poetry.lock"]
        }
      ],
      "gitignore": ["*.pyc", "__pycache__/", ".DS_Store"]
    }
""")


def classify_changes(model: str, files: list[str], diff_summary: str) -> tuple[list[dict], list[str]]:
    """Ask the model to group files into logical commits. Returns (commits, gitignore_patterns)."""
    file_list = "\n".join(f"  - {f}" for f in files)
    prompt = (
        f"{SYSTEM_PROMPT}\n\n"
        f"Changed files:\n{file_list}\n\n"
        f"Diffs:\n{diff_summary}"
    )

    raw = call_ollama(model, prompt)

    # Strip any accidental markdown fences the model might add
    raw = raw.strip()
    if raw.startswith("```"):
        lines = raw.splitlines()
        raw = "\n".join(lines[1:-1] if lines[-1].strip() == "```" else lines[1:])

    try:
        result = json.loads(raw)
    except json.JSONDecodeError as e:
        print(f"Error: Model returned invalid JSON: {e}", file=sys.stderr)
        print(f"Raw output:\n{raw}", file=sys.stderr)
        sys.exit(2)

    # Support both new object schema {"commits": [...], "gitignore": [...]}
    # and old array schema [...] for backwards compatibility
    if isinstance(result, list):
        commits_raw = result
        gitignore = []
    elif isinstance(result, dict):
        commits_raw = result.get("commits", [])
        gitignore = result.get("gitignore", [])
    else:
        print("Error: Model returned unexpected structure.", file=sys.stderr)
        sys.exit(2)

    # Validate each entry — accept both "subject" (new) and "message" (old) keys
    valid = []
    for item in commits_raw:
        if not isinstance(item, dict):
            continue
        if "subject" in item and "files" in item:
            valid.append(item)
        elif "message" in item and "files" in item:
            # normalise old schema to new
            valid.append({"subject": item["message"], "body": "", "files": item["files"]})

    if not valid:
        print("Error: Model returned no valid commit groups.", file=sys.stderr)
        sys.exit(2)

    return valid, gitignore


# ── Commit execution ───────────────────────────────────────────────────────────

def execute_commits(repo: Path, commits: list[dict]) -> None:
    """Stage and commit each group in order."""
    for i, commit in enumerate(commits, 1):
        subject = commit["subject"]
        body = commit.get("body", "").strip()
        message = f"{subject}\n\n{body}" if body else subject
        files = commit["files"]

        print(f"\n[{i}/{len(commits)}] {subject}")

        # Stage the files for this commit
        for f in files:
            try:
                git(["add", "--", f], repo)
                print(f"  + {f}")
            except RuntimeError as e:
                print(f"  ! Could not stage {f}: {e}", file=sys.stderr)

        # Check something is actually staged
        staged = git(["diff", "--cached", "--name-only"], repo).strip()
        if not staged:
            print("  (nothing staged, skipping)")
            continue

        try:
            git(["commit", "-m", message], repo)
            print(f"  ✓ Committed")
        except RuntimeError as e:
            print(f"  Error committing: {e}", file=sys.stderr)
            sys.exit(3)


# ── Display helpers ────────────────────────────────────────────────────────────

def print_proposed_commits(commits: list[dict], gitignore: list[str]) -> None:
    print("\nProposed commits:")
    print("─" * 60)
    for i, commit in enumerate(commits, 1):
        print(f"\n  [{i}] {commit['subject']}")
        body = commit.get("body", "").strip()
        if body:
            for line in body.splitlines():
                print(f"       {line}")
        for f in commit.get("files", []):
            print(f"       + {f}")
    if gitignore:
        print("\n  Suggested .gitignore patterns:")
        for pattern in gitignore:
            print(f"       {pattern}")
    print()


# ── Main ───────────────────────────────────────────────────────────────────────

def main() -> None:
    parser = argparse.ArgumentParser(
        description="Group git changes into logical commits using Qwen3-Coder.",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog=__doc__,
    )
    parser.add_argument("--repo", default=".", help="Path to git repository")
    parser.add_argument("--dry-run", action="store_true", help="Show proposed commits without executing")
    parser.add_argument("--model", default=DEFAULT_MODEL, help=f"Ollama model (default: {DEFAULT_MODEL})")
    parser.add_argument("--yes", "-y", action="store_true", help="Commit without confirmation")
    parser.add_argument("--json", dest="json_out", action="store_true", help="Output JSON and exit")

    args = parser.parse_args()
    repo = Path(args.repo).resolve()

    # Verify it's a git repo
    try:
        git(["rev-parse", "--git-dir"], repo)
    except RuntimeError:
        print(f"Error: {repo} is not a git repository.", file=sys.stderr)
        sys.exit(3)

    # Collect changed files
    print("Scanning for changes...", file=sys.stderr)
    files = get_changed_files(repo)
    if not files:
        print("No changes found.", file=sys.stderr)
        sys.exit(1)

    print(f"Found {len(files)} changed file(s). Analyzing...", file=sys.stderr)

    # Build stat summary and classify
    diff_summary = build_diff_summary(repo, args.model)
    commits, gitignore = classify_changes(args.model, files, diff_summary)

    # JSON mode: just dump and exit
    if args.json_out:
        print(json.dumps({"commits": commits, "gitignore": gitignore}, indent=2))
        return

    # Display proposed commits
    print_proposed_commits(commits, gitignore)

    if args.dry_run:
        return

    # Confirm unless --yes
    if not args.yes:
        try:
            answer = input("Proceed with these commits? [y/N] ").strip().lower()
        except (KeyboardInterrupt, EOFError):
            print("\nCancelled.")
            sys.exit(4)
        if answer not in ("y", "yes"):
            print("Cancelled.")
            sys.exit(4)

    execute_commits(repo, commits)
    print("\nDone.")


if __name__ == "__main__":
    main()
