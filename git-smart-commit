#!/usr/bin/env -S uv run --script
# /// script
# requires-python = ">=3.11"
# dependencies = [
#   "httpx",
#   "pydantic",
# ]
# ///
"""
git-smart-commit: Analyze unstaged changes, group into logical commits, execute them.

Uses an LLM for classification. Supports Ollama (default) and any OpenAI-compatible
API (OpenRouter, Anthropic, Together, etc.) via --api-base.

Usage:
    git-smart-commit [--repo PATH] [--dry-run] [--model MODEL] [--yes]
                     [--api-base URL] [--api-key KEY]
    git-smart-commit --setup

Options:
    --repo PATH     Path to git repository (default: current directory)
    --dry-run       Print proposed commits without executing
    --model MODEL   Model name (default: qwen3-coder:30b-a3b-q8_0)
    --yes           Skip confirmation prompt and commit immediately
    --json          Output proposed commits as JSON and exit (implies --dry-run)
    --api-base URL  API base URL (default: http://localhost:11434 for Ollama)
                    Use https://openrouter.ai/api/v1 for OpenRouter, etc.
    --api-key KEY   API key for authenticated endpoints (or set LLM_API_KEY env var)
    --setup         Run interactive configuration wizard and exit
    --help          Show this message
"""

from pathlib import Path
from pydantic import BaseModel, Field, ValidationError
from typing import Any, Callable

import argparse
import ast
import getpass
import httpx
import json
import os
import re
import subprocess
import sys
import tempfile
import textwrap
from dataclasses import dataclass, field

# ── Configuration ──────────────────────────────────────────────────────────────

SYSTEM_PROMPT = textwrap.dedent("""\
    You are a senior software engineer helping organize messy working-tree changes
    into clean, logical git commits.

    Given a list of changed files and their diffs, your job is to group them into
    one or more commits. Each commit should represent a single logical change
    (e.g. "add feature X", "fix bug in Y", "update dependencies",
    "refactor Z").

    You do not need to commit every file. Skip junk files (editor backups,
    build artifacts, OS metadata). Instead, collect suggested .gitignore patterns
    for them in the gitignore argument.

    You also actively look for common coding issues that a linter
    would catch and code smells such as using conditionals where
    polymorphism is more appropriate or violations of the Law of
    Demeter: misused APIs, suspicious code patterns, etc. For example:

    ```java
    // missing if braces
    if (a == 1) # wrong, add an issue "missing braces for if statement"
       b;
       c;
    d;
    ```

    ```c
    // incorrect arguments for well-known functions and Constructors
    printf(1); # wrong, add an issue "printf called with invalid arguments"
    ```

    ```python
    // Wrong keyword for the programming language
    if True:
        throw new Exception("foo") # wrong, add an issue "invalid keywords for python"

    ```

    ```python
    # Using exceptions for control flow instead of sys.exit
    if answer == "no":
        raise Exception("Cancelled.")  # wrong: should be sys.exit(0) or return
    ```

    Any detected issues should be added to the list of issues in a
    particular commit.

    Rules:
    - CRITICAL: Tool calls must use JSON for arguments. Other formats will result in failure. In particular, strings must be surrounded by double-quotes (") and if one occurs literally, escape with backslashes.
    - Changes are represented as individual diff hunks, each identified by an ID
      like "src/main.py#1". Untracked (new) files use "filepath#0".
    - You CAN split a file across multiple commits by assigning different hunks
      from that file to different commits. Prefer splitting when hunks are unrelated.
    - Keep related hunks together (same feature, same module, same concern).
    - Dependency/lockfile changes belong with the commit that caused them.
    - Test files belong with the code they test.
    - Use strict conventional commit format:
        subject: type(scope): short description  (under 72 chars)
        body: 4-10 lines, plain text, wrapped at 80 chars, no markdown
    - Type Definitions:
        * feat: Adds a net-new capability, flag, or behavior (e.g., adding .venv support, new CLI flags). Use this even for personal tools/dotfiles!
        * fix: Resolves a bug, crash, or incorrect behavior.
        * refactor: Structural changes that DO NOT change external behavior. If it adds a feature, it is a 'feat'.
        * chore: Routine maintenance, dependency bumps, or minor environment tweaks with no new logic.
        * (Other types: docs, test, style, build, ci)
    - feat is the highest priority commit type
    - chore is the lowest priority commit type
    - Do not repeat the commit type in the subject description (e.g., avoid "refactor(tools): refactor the parser").
    - Write body content based only on what you observe in the diff.
      Do not reference issue numbers or details not visible in the changes.
    - In the issues field, call out any bugs, incorrect API usage, or suspicious
      patterns you observe in the diff. Examples: wrong number of arguments,
      misused stdlib functions, unreachable code, obvious logic errors. Be specific:
      include the file, the offending line or pattern, and why it's wrong.
      Leave issues empty only if you find nothing suspicious.
    - Watch specifically for arguments passed to constructors or functions that
      don't accept them (e.g. Exception() does not accept a file= keyword argument).
    - BREAKING CHANGE detection: if a commit removes or renames a public function,
      class, or module; deletes an exported symbol; or changes a function/method
      signature incompatibly (added required param, removed param, changed type),
      set breaking_change to a concise description of what broke and how callers
      must update. Also add '!' after the type in the subject (e.g. 'feat!(api):').
      Leave breaking_change empty for purely additive or internal changes.

    You have access to a read_file tool. Use it when the diff alone is not
    enough context — for example, to see which class a changed function belongs
    to, what imports already exist, or how unchanged surrounding code looks.
    Call read_file as many times as needed, then call propose_commits when ready.
""")


AGENTIC_SYSTEM_PROMPT = textwrap.dedent("""\
    You are a senior software engineer helping organize messy working-tree changes
    into clean, logical git commits.

    You have investigation tools to gather information before proposing commits:
    - read_file(path): Read the full current content of any file in the repository
    - get_diff(path, staged): Get the raw diff for a specific file on demand
      (staged=true for staged only, staged=false for unstaged only, omit for both)
    - get_git_log(n): Get the last n commit subjects to learn this project's conventions
    - search_diff(pattern, context_lines): Search all diffs for a regex pattern

    Investigation strategy:
    - Start with the file list and stats you receive
    - Use get_git_log early to learn this project's commit style conventions
    - Use get_diff on files whose grouping is unclear from stats alone
    - Use read_file when you need full file context (imports, class structure, etc.)
    - Use search_diff to find patterns across all changes (debug prints, TODOs, etc.)
    - Investigate as many files as needed, then call propose_commits when confident

    You do not need to commit every file. Skip junk files (editor backups,
    build artifacts, OS metadata). Instead, collect suggested .gitignore patterns
    for them in the gitignore argument.

    You also actively look for common coding issues that a linter
    would catch and code smells such as using conditionals where
    polymorphism is more appropriate or violations of the Law of
    Demeter: misused APIs, suspicious code patterns, etc. For example:

    ```java
    // missing if braces
    if (a == 1) # wrong, add an issue "missing braces for if statement"
       b;
       c;
    d;
    ```

    ```c
    // incorrect arguments for well-known functions and Constructors
    printf(1); # wrong, add an issue "printf called with invalid arguments"
    ```

    ```python
    // Wrong keyword for the programming language
    if True:
        throw new Exception("foo") # wrong, add an issue "invalid keywords for python"

    ```

    ```python
    # Using exceptions for control flow instead of sys.exit
    if answer == "no":
        raise Exception("Cancelled.")  # wrong: should be sys.exit(0) or return
    ```

    Any detected issues should be added to the list of issues in a
    particular commit.

    Rules:
    - CRITICAL: Tool calls must use JSON for arguments. Other formats will result in failure. In particular, strings must be surrounded by double-quotes (") and if one occurs literally, escape with backslashes.
    - Changes are represented as individual diff hunks, each identified by an ID
      like "src/main.py#1". Untracked (new) files use "filepath#0".
    - You CAN split a file across multiple commits by assigning different hunks
      from that file to different commits. Prefer splitting when hunks are unrelated.
    - Keep related hunks together (same feature, same module, same concern).
    - Dependency/lockfile changes belong with the commit that caused them.
    - Test files belong with the code they test.
    - Use strict conventional commit format:
        subject: type(scope): short description  (under 72 chars)
        body: 4-10 lines, plain text, wrapped at 80 chars, no markdown
    - Type Definitions:
        * feat: Adds a net-new capability, flag, or behavior (e.g., adding .venv support, new CLI flags). Use this even for personal tools/dotfiles!
        * fix: Resolves a bug, crash, or incorrect behavior.
        * refactor: Structural changes that DO NOT change external behavior. If it adds a feature, it is a 'feat'.
        * chore: Routine maintenance, dependency bumps, or minor environment tweaks with no new logic.
        * (Other types: docs, test, style, build, ci)
    - feat is the highest priority commit type
    - chore is the lowest priority commit type
    - Do not repeat the commit type in the subject description (e.g., avoid "refactor(tools): refactor the parser").
    - Write body content based only on what you observe in the diff.
      Do not reference issue numbers or details not visible in the changes.
    - In the issues field, call out any bugs, incorrect API usage, or suspicious
      patterns you observe in the diff. Examples: wrong number of arguments,
      misused stdlib functions, unreachable code, obvious logic errors. Be specific:
      include the file, the offending line or pattern, and why it's wrong.
      Leave issues empty only if you find nothing suspicious.
    - Watch specifically for arguments passed to constructors or functions that
      don't accept them (e.g. Exception() does not accept a file= keyword argument).
    - BREAKING CHANGE detection: if a commit removes or renames a public function,
      class, or module; deletes an exported symbol; or changes a function/method
      signature incompatibly (added required param, removed param, changed type),
      set breaking_change to a concise description of what broke and how callers
      must update. Also add '!' after the type in the subject (e.g. 'feat!(api):').
      Leave breaking_change empty for purely additive or internal changes.

    When you have investigated enough to be confident in your groupings, call the
    propose_commits tool with your answer.
""")


OLLAMA_BASE_URL = "http://localhost:11434"
DEFAULT_MODEL = "gpt-oss:20b"

DIFF_CHARS_PER_FILE = 6000    # files larger than this get hunk-summarized
DIFF_TOTAL_CHARS   = 120000   # hard cap on total context sent to classifier
HUNK_SUMMARIZE_CTX = 8192     # smaller context for summarization calls (faster)
PRIOR_HUNK_WINDOW  = 4        # how many previous hunk summaries to include as context

MAX_AGENTIC_TURNS  = 20       # safeguard for the agentic investigation loop
READ_FILE_LIMIT    = 50_000   # max chars returned by the read_file tool

# Preset backends for the setup wizard
SETUP_BACKENDS = [
    {
        "key": "ollama",
        "label": "Ollama  (local, no API key needed)",
        "api_base": OLLAMA_BASE_URL,
        "default_model": DEFAULT_MODEL,
        "needs_key": False,
    },
    {
        "key": "openrouter",
        "label": "OpenRouter  (cloud, API key required)",
        "api_base": "https://openrouter.ai/api/v1",
        "default_model": "anthropic/claude-3.5-sonnet",
        "needs_key": True,
    },
    {
        "key": "anthropic",
        "label": "Anthropic  (cloud, API key required)",
        "api_base": "https://api.anthropic.com/v1",
        "default_model": "claude-sonnet-4-6",
        "needs_key": True,
    },
    {
        "key": "custom",
        "label": "Custom endpoint",
        "api_base": None,
        "default_model": None,
        "needs_key": None,
    },
]


@dataclass
class ApiConfig:
    """API connection and model configuration."""
    base_url: str = OLLAMA_BASE_URL
    model: str = DEFAULT_MODEL
    api_key: str | None = None
    num_ctx: int = 128000

    @property
    def is_ollama(self) -> bool:
        """True when targeting a native Ollama endpoint (not OpenAI-compatible)."""
        # OpenAI-compatible APIs use /v1 in the path; Ollama doesn't.
        return "/v1" not in self.base_url

    @property
    def chat_url(self) -> str:
        if self.is_ollama:
            return f"{self.base_url}/api/chat"
        return f"{self.base_url}/chat/completions"

    @property
    def auth_headers(self) -> dict[str, str]:
        if self.api_key:
            return {"Authorization": f"Bearer {self.api_key}"}
        return {}


@dataclass
class DiffHunk:
    """A single diff hunk that can be independently staged via git apply --cached."""
    hunk_id: str        # e.g. "src/main.py#1" or "src/main.py#0" for untracked new files
    file_path: str      # repository-relative path
    patch: str          # complete patch text for git apply --cached; empty for untracked
    is_untracked: bool = False


@dataclass
class ToolCall:
    """Represents a tool call extracted from an LLM response."""
    name: str
    arguments: dict
    call_id: str | None = None


# ── Tool decorator ─────────────────────────────────────────────────────────────
#
# Defining a new tool:
#   1. Define argument types as pydantic BaseModel subclasses
#   2. Define a top-level args model (also a BaseModel) for the tool
#   3. Decorate a function with @tool(ArgsModel)
#
# Schema generation, validation, and parsing are all handled automatically.

def tool(args_model: type[BaseModel]):
    """Decorator factory. @tool(MyArgsModel) attaches LLM tool metadata to a function."""
    def decorator(fn: Callable) -> Callable:
        spec = {
            "type": "function",
            "function": {
                "name": fn.__name__,
                "description": (fn.__doc__ or "").strip(),
                "parameters": args_model.model_json_schema(),
            },
        }
        fn._tool_spec = spec
        fn._tool_model = args_model
        return fn
    return decorator


def _summarize_args(arguments: dict, max_len: int = 80) -> str:
    """Return a compact one-line summary of tool call arguments for logging."""
    raw = json.dumps(arguments, separators=(",", ":"))
    if len(raw) <= max_len:
        return raw
    return raw[:max_len - 3] + "..."


# ── LLM client ────────────────────────────────────────────────────────────────

@dataclass
class TokenUsage:
    """Accumulated token usage across all API calls in a session."""
    prompt_tokens: int = 0
    completion_tokens: int = 0

    def __add__(self, other: "TokenUsage") -> "TokenUsage":
        return TokenUsage(
            prompt_tokens=self.prompt_tokens + other.prompt_tokens,
            completion_tokens=self.completion_tokens + other.completion_tokens,
        )

    @property
    def total_tokens(self) -> int:
        return self.prompt_tokens + self.completion_tokens

    def __str__(self) -> str:
        return (f"{self.total_tokens:,} tokens "
                f"({self.prompt_tokens:,} in / {self.completion_tokens:,} out)")


class LLMClient:
    """Encapsulates all communication with the LLM API (Ollama or OpenAI-compatible)."""

    def __init__(self, config: ApiConfig):
        self.config = config
        self.usage = TokenUsage()

    def _build_payload(self, prompt: str, tools: list[dict] | None = None,
                       stream: bool = False) -> dict:
        """Build an API request payload, adapting to Ollama or OpenAI format."""
        if self.config.is_ollama:
            payload: dict[str, Any] = {
                "model": self.config.model,
                "messages": [{"role": "user", "content": prompt}],
                "stream": stream,
                "keep_alive": "1h",
                "options": {
                    "temperature": 0.2,
                    "num_ctx": self.config.num_ctx,
                },
            }
            if tools:
                payload["tools"] = tools
        else:
            payload = {
                "model": self.config.model,
                "messages": [{"role": "user", "content": prompt}],
                "stream": stream,
                "temperature": 0.2,
            }
            if tools:
                payload["tools"] = tools
                # Force the model to call the specific tool
                payload["tool_choice"] = {
                    "type": "function",
                    "function": {"name": tools[0]["function"]["name"]},
                }
        return payload

    def _extract_tool_args(self, data: dict) -> dict | None:
        """Extract tool-call arguments from a response, handling both API formats."""
        if self.config.is_ollama:
            tool_calls = data.get("message", {}).get("tool_calls", [])
            if tool_calls:
                raw = tool_calls[0]["function"]["arguments"]
                return json.loads(raw) if isinstance(raw, str) else raw
            # Fallback: content as JSON
            content = data.get("message", {}).get("content", "").strip()
        else:
            choices = data.get("choices", [])
            if not choices:
                return None
            msg = choices[0].get("message", {})
            tool_calls = msg.get("tool_calls", [])
            if tool_calls:
                raw = tool_calls[0]["function"]["arguments"]
                return json.loads(raw) if isinstance(raw, str) else raw
            content = msg.get("content", "").strip()

        # Fallback: parse content as JSON (both backends)
        if content:
            content = content.removeprefix("```json").removeprefix("```").strip().removesuffix("```").strip()
            return json.loads(content)
        return None

    def _build_payload_messages(self, messages: list[dict],
                                tools: list[dict] | None = None,
                                tool_choice: str | dict | None = None,
                                stream: bool = False) -> dict:
        """Build a payload from a full conversation history (messages list)."""
        if self.config.is_ollama:
            payload: dict[str, Any] = {
                "model": self.config.model,
                "messages": messages,
                "stream": stream,
                "keep_alive": "1h",
                "options": {
                    "temperature": 0.2,
                    "num_ctx": self.config.num_ctx,
                },
            }
            if tools:
                payload["tools"] = tools
            # Ollama does not support tool_choice — omit it
        else:
            payload = {
                "model": self.config.model,
                "messages": messages,
                "stream": stream,
                "temperature": 0.2,
            }
            if tools:
                payload["tools"] = tools
            if tool_choice is not None:
                payload["tool_choice"] = tool_choice
        return payload

    def _extract_tool_call(self, data: dict) -> ToolCall | None:
        """Extract a tool call from an API response, handling both Ollama and OpenAI formats."""
        if self.config.is_ollama:
            tool_calls = data.get("message", {}).get("tool_calls", [])
            if tool_calls:
                tc = tool_calls[0]
                raw = tc["function"]["arguments"]
                args = json.loads(raw) if isinstance(raw, str) else raw
                return ToolCall(
                    name=tc["function"]["name"],
                    arguments=args,
                    call_id=tc.get("id"),
                )
        else:
            choices = data.get("choices", [])
            if not choices:
                return None
            msg = choices[0].get("message", {})
            tool_calls = msg.get("tool_calls", [])
            if tool_calls:
                tc = tool_calls[0]
                raw = tc["function"]["arguments"]
                args = json.loads(raw) if isinstance(raw, str) else raw
                return ToolCall(
                    name=tc["function"]["name"],
                    arguments=args,
                    call_id=tc.get("id"),
                )
        return None

    def _extract_text_content(self, data: dict) -> str | None:
        """Extract plain text content from a response when no tool call is present."""
        if self.config.is_ollama:
            content = data.get("message", {}).get("content", "").strip()
        else:
            choices = data.get("choices", [])
            if not choices:
                return None
            content = choices[0].get("message", {}).get("content", "").strip()
        return content or None

    def _format_assistant_tool_call(self, data: dict) -> dict:
        """Extract the assistant message from a raw API response for conversation history.

        Using the raw response message guarantees the format Ollama/OpenAI expects to see back.
        """
        if self.config.is_ollama:
            return data.get("message", {"role": "assistant", "content": ""})
        return data.get("choices", [{}])[0].get("message", {"role": "assistant", "content": ""})

    def _format_tool_result(self, call_id: str | None, content: str) -> dict:
        """Build a tool-result message for appending to conversation history."""
        if call_id is not None and not self.config.is_ollama:
            return {"role": "tool", "tool_call_id": call_id, "content": content}
        return {"role": "tool", "content": content}

    def _extract_usage(self, data: dict) -> TokenUsage:
        """Extract token usage from an API response (Ollama or OpenAI format)."""
        if self.config.is_ollama:
            return TokenUsage(
                prompt_tokens=data.get("prompt_eval_count", 0),
                completion_tokens=data.get("eval_count", 0),
            )
        usage = data.get("usage", {})
        return TokenUsage(
            prompt_tokens=usage.get("prompt_tokens", 0),
            completion_tokens=usage.get("completion_tokens", 0),
        )

    def call(self, prompt: str, num_ctx: int | None = None) -> str:
        """Call the LLM with streaming and return the assistant message text."""
        payload = self._build_payload(prompt, stream=True)
        if num_ctx is not None and self.config.is_ollama:
            payload["options"]["num_ctx"] = num_ctx
        headers = {**self.config.auth_headers, "Content-Type": "application/json"}
        with httpx.Client(timeout=httpx.Timeout(connect=30.0, read=60.0, write=30.0, pool=5.0)) as client:
            with client.stream("POST", self.config.chat_url, json=payload, headers=headers) as response:
                response.raise_for_status()
                chunks = []
                for line in response.iter_lines():
                    if not line:
                        continue
                    # OpenAI SSE format: lines prefixed with "data: "
                    if line.startswith("data: "):
                        line = line[6:]
                    if line.strip() == "[DONE]":
                        break
                    try:
                        data = json.loads(line)
                    except json.JSONDecodeError:
                        continue
                    if self.config.is_ollama:
                        content = data.get("message", {}).get("content", "")
                        done = data.get("done", False)
                    else:
                        delta = (data.get("choices", [{}])[0]
                                 .get("delta", {}))
                        content = delta.get("content", "")
                        done = data.get("choices", [{}])[0].get("finish_reason") is not None
                    if content:
                        chunks.append(content)
                    if done:
                        self.usage = self.usage + self._extract_usage(data)
                        break
                return "".join(chunks)

    def call_with_tool(self, prompt: str, tool_fn: Callable, **tool_kwargs) -> Any:
        """Call the LLM forcing tool_fn to be called.

        Parses and validates the response into the tool's args model, then calls
        tool_fn(validated_args, **tool_kwargs) and returns its result.
        """
        spec = tool_fn._tool_spec
        args_model: type[BaseModel] = tool_fn._tool_model
        actual_prompt = prompt
        retries = 0
        failures = []
        while True:
            retries += 1
            payload = self._build_payload(actual_prompt, tools=[spec], stream=False)
            headers = {**self.config.auth_headers, "Content-Type": "application/json"}
            with httpx.Client(timeout=httpx.Timeout(connect=30.0, read=300.0, write=30.0, pool=5.0)) as client:
                response = client.post(self.config.chat_url, json=payload, headers=headers)
                response.raise_for_status()
                data = response.json()
            self.usage = self.usage + self._extract_usage(data)

            raw_args = self._extract_tool_args(data)
            if raw_args is None:
                raw_args = {}

            # Fix stringified nested values: some models return e.g.
            # {"commits": "[{'subject': ...}]"} instead of a proper nested structure.
            # Detect strings that look like Python lists/dicts and try to parse them.
            for key, val in raw_args.items():
                if isinstance(val, str) and val.strip().startswith(("[", "{")):
                    try:
                        raw_args[key] = json.loads(val)
                    except json.JSONDecodeError:
                        try:
                            raw_args[key] = ast.literal_eval(val)
                        except (ValueError, SyntaxError):
                            pass  # leave as-is, let pydantic report the error

            try:
                validated = args_model.model_validate(raw_args).post_process()
                return tool_fn(validated, **tool_kwargs)
            except ValidationError as e:
                failures.append(str(e))
                if retries > 5:
                    raise

                failure_summary = "\n".join(set(failures))
                actual_prompt = textwrap.dedent(f"""
                Your previous ({len(failures)}) attempts failed with a validation error:
                {failure_summary}

                Try again following this prompt exactly:
                {prompt}
                """)

    def agentic_loop(self, system_prompt: str, initial_user_message: str,
                     tool_registry: dict[str, Callable],
                     terminal_tool: Callable, **kwargs) -> Any:
        """Run a multi-turn agentic loop until the terminal tool is called.

        Each turn: send messages → extract tool call → dispatch.
        Investigation tool results are appended to history.
        Validation errors for the terminal tool become tool-result messages.
        On the last turn, only the terminal tool is offered.
        """
        messages: list[dict] = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": initial_user_message},
        ]

        terminal_spec = terminal_tool._tool_spec
        terminal_name: str = terminal_spec["function"]["name"]
        terminal_model: type[BaseModel] = terminal_tool._tool_model
        all_tool_specs = [fn._tool_spec for fn in list(tool_registry.values())] + [terminal_spec]

        headers = {**self.config.auth_headers, "Content-Type": "application/json"}

        for turn in range(1, MAX_AGENTIC_TURNS + 1):
            is_last_turn = (turn == MAX_AGENTIC_TURNS)

            if is_last_turn:
                tools = [terminal_spec]
                tool_choice: str | dict | None = (
                    None if self.config.is_ollama
                    else {"type": "function", "function": {"name": terminal_name}}
                )
            else:
                tools = all_tool_specs
                tool_choice = None if self.config.is_ollama else "auto"

            payload = self._build_payload_messages(messages, tools=tools,
                                                   tool_choice=tool_choice, stream=False)

            with httpx.Client(timeout=httpx.Timeout(connect=30.0, read=300.0, write=30.0, pool=5.0)) as client:
                response = client.post(self.config.chat_url, json=payload, headers=headers)
                response.raise_for_status()
                data = response.json()
            self.usage = self.usage + self._extract_usage(data)

            tool_call = self._extract_tool_call(data)

            if tool_call is None:
                text = self._extract_text_content(data) or ""
                print(f"  [agentic turn {turn}/{MAX_AGENTIC_TURNS}] no tool call, nudging",
                      file=sys.stderr)
                messages.append({"role": "assistant", "content": text})
                messages.append({
                    "role": "user",
                    "content": (
                        f"Please call a tool. Use the investigation tools to gather more "
                        f"information, or call {terminal_name} if you are ready to propose commits."
                    ),
                })
                continue

            print(f"  [agentic turn {turn}/{MAX_AGENTIC_TURNS}] "
                  f"{tool_call.name}({_summarize_args(tool_call.arguments)})",
                  file=sys.stderr)
            messages.append(self._format_assistant_tool_call(data))

            # Coerce stringified nested values (some models return JSON-as-string)
            raw_args = dict(tool_call.arguments)
            for key, val in raw_args.items():
                if isinstance(val, str) and val.strip().startswith(("[", "{")):
                    try:
                        raw_args[key] = json.loads(val)
                    except json.JSONDecodeError:
                        try:
                            raw_args[key] = ast.literal_eval(val)
                        except (ValueError, SyntaxError):
                            pass

            if tool_call.name == terminal_name:
                try:
                    validated = terminal_model.model_validate(raw_args).post_process()
                    return terminal_tool(validated, **kwargs)
                except ValidationError as e:
                    messages.append(self._format_tool_result(
                        tool_call.call_id,
                        f"Validation error: {e}\nPlease fix the arguments and call "
                        f"{terminal_name} again.",
                    ))
                    continue

            tool_fn = tool_registry.get(tool_call.name)
            if tool_fn is None:
                result_str = (f"Unknown tool: {tool_call.name!r}. "
                              f"Available: {list(tool_registry.keys())}")
            else:
                try:
                    validated_args = tool_fn._tool_model.model_validate(raw_args).post_process()
                    result = tool_fn(validated_args, **kwargs)
                    result_str = result if isinstance(result, str) else json.dumps(result)
                except Exception as e:
                    result_str = f"Error calling {tool_call.name}: {e}"

            messages.append(self._format_tool_result(tool_call.call_id, result_str))

        raise RuntimeError(
            f"agentic_loop exceeded {MAX_AGENTIC_TURNS} turns without calling {terminal_name}"
        )



# ── Git helpers ────────────────────────────────────────────────────────────────

def _git(args: list[str], cwd: Path) -> str:
    """Run a git command and return stdout. Raises on non-zero exit."""
    result = subprocess.run(
        ["git"] + args,
        cwd=cwd,
        capture_output=True,
        text=True,
    )
    if result.returncode != 0:
        raise RuntimeError(f"git {' '.join(args)} failed:\n{result.stderr.strip()}")
    return result.stdout


def read_git_config(repo: Path) -> dict[str, str]:
    """Read smart-commit.* keys from git config (local → global → system).

    Returns a dict of whichever keys are set; missing keys are absent.
    Keys: smart-commit.model, smart-commit.api-base, smart-commit.api-key
    """
    keys = ["smart-commit.model", "smart-commit.api-base", "smart-commit.api-key"]
    config: dict[str, str] = {}
    for key in keys:
        result = subprocess.run(
            ["git", "config", "--get", key],
            cwd=repo,
            capture_output=True,
            text=True,
        )
        if result.returncode == 0 and result.stdout.strip():
            config[key] = result.stdout.strip()
    return config


def _prompt(message: str, default: str | None = None) -> str | None:
    """Prompt the user for input, returning the default on empty entry.

    Returns None if the user presses Ctrl-C or Ctrl-D.
    """
    try:
        raw = input(message).strip()
    except (KeyboardInterrupt, EOFError):
        return None
    return raw if raw else default


def run_setup_wizard(repo: Path | None) -> None:
    """Interactive wizard to configure git-smart-commit via git config.

    Prompts for API backend, model, API key, and config scope (global / local).
    Writes settings with ``git config``.

    Args:
        repo: Path to a git repository (required for local scope).
              May be None when only global scope is needed.
    """
    print()
    print("git-smart-commit setup wizard")
    print("=" * 40)
    print()

    # ── Step 1: choose backend ────────────────────────────────────────────────
    print("Select API backend:")
    for i, b in enumerate(SETUP_BACKENDS, 1):
        marker = "  ← default" if i == 1 else ""
        print(f"  [{i}] {b['label']}{marker}")
    print()

    backend_choice = _prompt("Choice [1]: ", default="1")
    if backend_choice is None:
        print("\nSetup cancelled.")
        return
    try:
        backend_idx = int(backend_choice) - 1
        if not 0 <= backend_idx < len(SETUP_BACKENDS):
            raise ValueError
    except ValueError:
        print("Invalid choice. Setup cancelled.")
        return

    backend = SETUP_BACKENDS[backend_idx]
    print()

    # ── Step 2: API base URL (custom only) ───────────────────────────────────
    api_base: str
    if backend["api_base"] is None:
        val = _prompt("API base URL: ")
        if not val:
            print("URL required. Setup cancelled.")
            return
        api_base = val.rstrip("/")
    else:
        api_base = backend["api_base"]

    # ── Step 3: model ─────────────────────────────────────────────────────────
    default_model: str = backend["default_model"] or ""
    model_prompt = f"Model [{default_model}]: " if default_model else "Model: "
    model_val = _prompt(model_prompt, default=default_model)
    if model_val is None:
        print("\nSetup cancelled.")
        return
    if not model_val:
        print("Model name required. Setup cancelled.")
        return
    model = model_val

    # ── Step 4: API key ───────────────────────────────────────────────────────
    api_key: str | None = None
    needs_key: bool | None = backend["needs_key"]
    if needs_key is True:
        try:
            api_key = getpass.getpass("API key (input hidden): ").strip() or None
        except (KeyboardInterrupt, EOFError):
            print("\nSetup cancelled.")
            return
        if not api_key:
            print("API key required for this backend. Setup cancelled.")
            return
    elif needs_key is None:
        # custom endpoint — key is optional
        try:
            raw_key = getpass.getpass("API key (leave empty if not needed, input hidden): ").strip()
        except (KeyboardInterrupt, EOFError):
            print("\nSetup cancelled.")
            return
        api_key = raw_key or None

    print()

    # ── Step 5: config scope ──────────────────────────────────────────────────
    print("Save configuration to:")
    print("  [1] Global  (~/.gitconfig)  ← affects all repos  [default]")
    if repo is not None:
        print("  [2] Local   (.git/config)   ← this repo only")
    print()

    scope_choice = _prompt("Choice [1]: ", default="1")
    if scope_choice is None:
        print("\nSetup cancelled.")
        return

    scope_flag: str
    if scope_choice == "2" and repo is not None:
        scope_flag = "--local"
        scope_label = f"local ({repo})"
    else:
        scope_flag = "--global"
        scope_label = "global (~/.gitconfig)"

    print()

    # ── Step 6: write config ──────────────────────────────────────────────────
    cwd = repo if repo is not None else Path.cwd()

    settings: list[tuple[str, str]] = [
        ("smart-commit.api-base", api_base),
        ("smart-commit.model", model),
    ]
    if api_key:
        settings.append(("smart-commit.api-key", api_key))

    print(f"Writing {scope_label} config...")
    for key, value in settings:
        cmd = ["git", "config", scope_flag, key, value]
        result = subprocess.run(cmd, cwd=cwd, capture_output=True, text=True)
        if result.returncode != 0:
            print(f"  Error setting {key}: {result.stderr.strip()}", file=sys.stderr)
            sys.exit(1)
        # Redact the API key in output
        display_value = "***" if "api-key" in key else value
        print(f"  git config {scope_flag} {key} {display_value}")

    print()
    print("Done! Run git-smart-commit to use your new settings.")
    if api_key:
        print()
        print("Tip: your API key is stored in plaintext in git config.")
        print("     Consider using the LLM_API_KEY environment variable instead.")
    print()


def split_hunks(diff_text: str) -> list[str]:
    """Split a unified diff into individual hunks (each starting with @@)."""
    lines = diff_text.splitlines(keepends=True)
    hunks: list[str] = []
    header_lines: list[str] = []
    current: list[str] = []

    for line in lines:
        if line.startswith("@@"):
            if current:
                hunks.append("".join(current))
            current = header_lines + [line]
        elif line.startswith(("diff --git", "index ", "--- ", "+++ ")):
            header_lines.append(line)
            if current:
                # flush any open hunk first
                hunks.append("".join(current))
                current = []
        else:
            if current:
                current.append(line)
            # lines before the first @@ go into header_lines
            elif not line.startswith("@@"):
                header_lines.append(line)

    if current:
        hunks.append("".join(current))

    return hunks or [diff_text]   # fallback: treat whole diff as one hunk


# ── Tool definitions ───────────────────────────────────────────────────────────

class Issue(BaseModel):
    message: str = Field(description="REQUIRED. A brief description of a code issue, including a line number")
    path: str = Field(description="REQUIRED. The path affected by the issue")

class Commit(BaseModel):
    subject: str = Field(description="REQUIRED. Conventional commit subject line (type(scope): desc), under 72 chars. Add '!' after the type when a breaking change is present (e.g. 'feat!(api): rename endpoint').")
    hunks: list[str] = Field(description="REQUIRED. Hunk IDs to include in this commit, e.g. ['src/main.py#1', 'src/main.py#3']. New untracked files use 'filepath#0'.")
    body: str = Field(default="", description="4-10 line plain-text commit body, no markdown")
    breaking_change: str = Field(default="", description="If this commit removes or renames a public API, changes a function signature incompatibly, or deletes an exported symbol, describe what broke and how callers must migrate. Leave empty if there is no breaking change.")
    issues: list[Issue] = Field(default_factory=list, description="Issues noticed in the code being committed")

    def post_process(self):
        self.body = textwrap.fill(self.body, 80)
        self.breaking_change = textwrap.fill(self.breaking_change, 80)
        return self

class ProposeCommitsArgs(BaseModel):
    commits: list[Commit] = Field(description="REQUIRED. Logical commit groups")
    gitignore: list[str] = Field(default_factory=list, description="Suggested .gitignore patterns for junk files")

    def post_process(self):
        self.commits = [commit.post_process() for commit in self.commits]
        return self

sample_issue = Issue(
    message="Unused import 'os' on line 1",
    path="main.py"
)

sample_commit = Commit(
    subject="refactor(main): cleanup imports",
    hunks=["main.py#1"],
    body="Removed unnecessary imports to improve load time and code cleanliness.",
    issues=[sample_issue]
)

SAMPLE_OUTPUT = ProposeCommitsArgs(
    commits=[sample_commit],
    gitignore=["*.pyc", "__pycache__/"]
)


@tool(ProposeCommitsArgs)
def propose_commits(result: ProposeCommitsArgs, analyzer: "GitAnalyzer") -> tuple[list[dict], list[str]]:
    """Group working-tree changes into logical commits and suggest .gitignore patterns for junk files."""
    commits = [c.model_dump() for c in result.commits]
    if not commits:
        raise ValueError("Model returned no valid commit groups.")

    commits = analyzer.merge_overlapping_commits(commits)
    return commits, result.gitignore


class MergeCommitsArgs(BaseModel):
    commit: Commit = Field(description="REQUIRED. A single merged commit covering all the provided changes")
    gitignore: list[str] = Field(default_factory=list, description="Suggested .gitignore patterns for junk files")

    def post_process(self):
        self.commit = self.commit.post_process()
        return self


@tool(MergeCommitsArgs)
def merge_commits(result: MergeCommitsArgs, all_hunks: list[str], all_issues: list[dict]) -> dict:
    """Merge multiple overlapping commits into a single coherent commit."""
    commit = result.commit.model_dump()
    # Ensure all hunks and issues are preserved regardless of what the model returns
    commit["hunks"] = all_hunks
    commit["issues"] = all_issues
    return commit


class ReadFileArgs(BaseModel):
    path: str = Field(description="Repository-relative path to the file to read")

    def post_process(self): return self


@tool(ReadFileArgs)
def read_file(args: ReadFileArgs, analyzer: "GitAnalyzer") -> str:
    """Read the full current content of a file in the repository.

    Use this when the diff alone lacks context — e.g. to see the surrounding
    class structure, existing imports, or unchanged code near a changed line.
    The result is truncated at 50,000 characters for very large files.
    """
    return analyzer._read_file(args.path)


class GetDiffArgs(BaseModel):
    path: str = Field(description="Repository-relative path of the file")
    staged: bool | None = Field(
        default=None,
        description="true=staged only, false=unstaged only, null/omit=both",
    )

    def post_process(self): return self


@tool(GetDiffArgs)
def get_diff(result: GetDiffArgs, analyzer: "GitAnalyzer") -> str:
    """Get the raw unified diff for a specific file (staged, unstaged, or both)."""
    parts = []

    def _fetch(extra_args: list[str], label: str) -> None:
        try:
            diff = analyzer.git(["diff"] + extra_args + ["--no-color", "--no-ext-diff", "--", result.path])
            if diff.strip():
                parts.append(f"=== {label} ===\n{diff}" if result.staged is None else diff)
        except RuntimeError as e:
            parts.append(f"Error ({label}): {e}")

    if result.staged is None:
        _fetch(["--cached"], "staged")
        _fetch([], "unstaged")
    elif result.staged:
        _fetch(["--cached"], "staged")
    else:
        _fetch([], "unstaged")

    result_text = "\n".join(parts) if parts else f"No diff found for {result.path}"

    if len(result_text) > DIFF_CHARS_PER_FILE:
        result_text = result_text[:DIFF_CHARS_PER_FILE] + f"\n\n... (truncated at {DIFF_CHARS_PER_FILE} chars)"

    return result_text


class GetGitLogArgs(BaseModel):
    n: int = Field(default=20, description="Number of recent commits to return (max 50)")

    def post_process(self): return self


@tool(GetGitLogArgs)
def get_git_log(result: GetGitLogArgs, analyzer: "GitAnalyzer") -> str:
    """Get recent commit history to understand this project's commit style conventions."""
    n = min(result.n, 50)
    try:
        log = analyzer.git(["log", f"--max-count={n}", "--oneline", "--no-color"])
        return log.strip() or "No commits found."
    except RuntimeError as e:
        return f"Error: {e}"


class SearchDiffArgs(BaseModel):
    pattern: str = Field(description="Python regex pattern to search for across all diffs")
    context_lines: int = Field(default=2, description="Lines of context around each match")

    def post_process(self): return self


@tool(SearchDiffArgs)
def search_diff(result: SearchDiffArgs, analyzer: "GitAnalyzer") -> str:
    """Search for a regex pattern across all staged and unstaged diffs."""
    try:
        compiled = re.compile(result.pattern)
    except re.error as e:
        return f"Invalid regex: {e}"

    matches: list[dict] = []
    MAX_MATCHES = 50

    for extra_args in (["--cached"], []):
        if len(matches) >= MAX_MATCHES:
            break
        try:
            changed = analyzer.git(
                ["diff"] + extra_args + ["--name-only", "--no-ext-diff"]
            ).splitlines()
            for fname in changed:
                if len(matches) >= MAX_MATCHES:
                    break
                diff = analyzer.git(
                    ["diff"] + extra_args + ["--no-color", "--no-ext-diff", "--", fname]
                )
                lines = diff.splitlines()
                for i, line in enumerate(lines):
                    if compiled.search(line):
                        start = max(0, i - result.context_lines)
                        end = min(len(lines), i + result.context_lines + 1)
                        matches.append({
                            "file": fname,
                            "line_number": i + 1,
                            "match_context": "\n".join(lines[start:end]),
                        })
                        if len(matches) >= MAX_MATCHES:
                            break
        except RuntimeError:
            pass

    if not matches:
        return f"No matches found for pattern: {result.pattern!r}"

    result_lines = [
        f"File: {m['file']} (line {m['line_number']})\n{m['match_context']}"
        for m in matches
    ]
    text = "\n---\n".join(result_lines)
    if len(matches) >= MAX_MATCHES:
        text += f"\n... (limited to {MAX_MATCHES} matches)"
    return text


MERGE_PROMPT = textwrap.dedent("""\
    You are merging multiple proposed commits that share the same diff hunks
    and therefore cannot be committed separately.

    Combine them into a SINGLE commit that:
    - Has one conventional commit subject line (type(scope): desc), under 72 chars
    - Has a body (4-10 lines) summarizing ALL the changes coherently
    - Lists ALL affected hunks (deduped)
    - Collects ALL issues (deduped)
    - If any commit is a feat type, it must take priority over the others (although the others should be mentioned in the commit body)
    - chore should only be used if no other category applies.
    - If any input commit has a non-empty breaking_change, set breaking_change on the merged commit to a combined description and add '!' to the type.

    Do NOT just concatenate the subjects. Write a new, coherent subject and body
    that covers the full set of changes as a single logical unit.

    Call the merge_commits tool with your answer.

    Here are the commits to merge:
""")


# ── GitAnalyzer ────────────────────────────────────────────────────────────────

class GitAnalyzer:
    """Encapsulates git operations and commit analysis for a repository."""

    def __init__(self, repo: Path, client: LLMClient):
        self.repo = repo
        self.client = client

    @property
    def config(self) -> ApiConfig:
        return self.client.config

    def git(self, args: list[str]) -> str:
        return _git(args, self.repo)

    def get_changed_files(self) -> list[str]:
        """Return list of files with unstaged or staged changes."""
        staged = self.git(["diff", "--cached", "--name-only"]).splitlines()
        unstaged = self.git(["diff", "--name-only"]).splitlines()
        untracked = self.git(["ls-files", "--others", "--exclude-standard"]).splitlines()
        seen = set()
        files = []
        for f in staged + unstaged + untracked:
            if f and f not in seen:
                seen.add(f)
                files.append(f)
        return files

    def collect_hunks(self) -> dict[str, DiffHunk]:
        """Collect all diff hunks from the working tree, indexed by hunk ID.

        Any currently staged changes are first unstaged (git reset HEAD) so that
        everything is treated uniformly as unstaged working-tree changes.  This is
        safe: working-tree content is never modified.

        Returns a dict mapping hunk_id → DiffHunk.  Hunk IDs for unstaged changes
        look like "path/file.py#1"; untracked new files use "path/file.py#0".
        """
        hunk_map: dict[str, DiffHunk] = {}

        # Unstage any staged files so we work uniformly with unstaged diffs
        staged_files = self.git(["diff", "--cached", "--name-only"]).splitlines()
        if staged_files:
            self.git(["reset", "HEAD", "--"] + staged_files)

        # Split each unstaged file's diff into individual hunks
        changed = self.git(["diff", "--name-only", "--no-ext-diff"]).splitlines()
        for fpath in changed:
            diff = self.git(["diff", "--no-color", "--no-ext-diff", "--", fpath])
            if not diff.strip():
                continue
            file_hunks = split_hunks(diff)
            for i, patch in enumerate(file_hunks, 1):
                hunk_id = f"{fpath}#{i}"
                hunk_map[hunk_id] = DiffHunk(
                    hunk_id=hunk_id,
                    file_path=fpath,
                    patch=patch,
                )

        # Untracked (new) files are staged whole via git add — use #0 suffix
        untracked = self.git(["ls-files", "--others", "--exclude-standard"]).splitlines()
        for fpath in untracked:
            hunk_id = f"{fpath}#0"
            hunk_map[hunk_id] = DiffHunk(
                hunk_id=hunk_id,
                file_path=fpath,
                patch="",
                is_untracked=True,
            )

        return hunk_map

    def build_hunk_context(self, hunk_map: dict[str, DiffHunk]) -> str:
        """Build the initial LLM message: hunk list with inline diff content.

        Small hunks are included verbatim; very large ones are summarized.
        Total output is capped at DIFF_TOTAL_CHARS.
        """
        parts: list[str] = []
        total_chars = 0

        # Header: compact hunk list
        hunk_list_lines = []
        for hunk_id, dh in hunk_map.items():
            if dh.is_untracked:
                hunk_list_lines.append(f"  {hunk_id}  (new untracked file)")
            else:
                adds = dh.patch.count("\n+") - dh.patch.count("\n+++")
                dels = dh.patch.count("\n-") - dh.patch.count("\n---")
                hunk_list_lines.append(f"  {hunk_id}  (+{adds}/-{dels})")
        parts.append("Available hunks:\n" + "\n".join(hunk_list_lines))

        # Inline diff content for each hunk
        diff_parts: list[str] = []
        for hunk_id, dh in hunk_map.items():
            if dh.is_untracked:
                diff_parts.append(f"--- {hunk_id} ---\n(new untracked file — no diff)")
                total_chars += 50
            elif len(dh.patch) <= DIFF_CHARS_PER_FILE:
                diff_parts.append(f"--- {hunk_id} ---\n{dh.patch}")
                total_chars += len(dh.patch)
            else:
                print(f"  Summarizing large hunk: {hunk_id} ({len(dh.patch):,} chars)…",
                      file=sys.stderr)
                summary = self._summarize_file_diff(dh.file_path, dh.patch)
                diff_parts.append(f"--- {hunk_id} ---\n{summary}")
                total_chars += len(summary)

            if total_chars >= DIFF_TOTAL_CHARS:
                diff_parts.append("\n... (remaining hunks omitted — total size limit reached)")
                break

        parts.append("\nDiff content:\n" + "\n\n".join(diff_parts))
        return "\n\n".join(parts)

    def build_file_metadata(self) -> str:
        """Return a compact stats-only summary: diff --stat for staged/unstaged + untracked list.

        No full diffs — the LLM requests specific diffs lazily via get_diff.
        """
        parts: list[str] = []
        for label, extra_args in [("Staged", ["--cached"]), ("Unstaged", [])]:
            stat = self.git(["diff"] + extra_args + ["--stat", "--no-color"]).strip()
            if stat:
                parts.append(f"{label}:\n{stat}")
        untracked = self.git(["ls-files", "--others", "--exclude-standard"]).splitlines()
        if untracked:
            parts.append("Untracked (new files):\n" + "\n".join(f"  {f}" for f in untracked))
        return "\n\n".join(parts)

    def _summarize_file_diff(self, fname: str, diff_text: str) -> str:
        """Ask the model to summarize each hunk, passing the last N summaries as context."""
        hunks = split_hunks(diff_text)
        hunk_summaries: list[str] = []

        for i, hunk in enumerate(hunks, 1):
            prior_context = ""
            if hunk_summaries:
                window = hunk_summaries[-PRIOR_HUNK_WINDOW:]
                start_idx = i - len(window)
                prior_context = "Previous hunks in this file:\n" + "\n".join(
                    f"  Hunk {start_idx + j}: {s}" for j, s in enumerate(window)
                ) + "\n\n"

            prompt = textwrap.dedent(f"""\
                Summarize hunk {i} of {len(hunks)} from '{fname}' in 1-3 plain English sentences.
                Focus on WHAT changed. Preserve verbatim any code that looks buggy or suspicious
                (wrong arguments, misused APIs, incorrect syntax). Output only the summary.

                {prior_context}Hunk {i}:
                {hunk}
            """)

            summary = self.client.call(prompt, num_ctx=HUNK_SUMMARIZE_CTX)
            hunk_summaries.append(summary.strip())

        print()
        return f"[summarized — {len(hunks)} hunk(s)]\n" + "\n".join(
            f"  Hunk {i}: {s}" for i, s in enumerate(hunk_summaries, 1)
        )

    def build_diff_summary(self) -> str:
        """Return diff context for the classifier.

        Small files: include raw diff.
        Large files: summarize each hunk via a fast model call, then include summaries.
        """
        parts: list[str] = []
        total_chars = 0

        for label, extra_args in [("Staged", ["--cached"]), ("Unstaged", [])]:
            stat = self.git(["diff"] + extra_args + ["--stat", "--no-color"]).strip()
            if not stat:
                continue
            parts.append(f"{label}:\n{stat}\n")

            changed = self.git(["diff"] + extra_args + ["--name-only", "--no-ext-diff"]).splitlines()
            for fname in changed:
                file_diff = self.git(["diff"] + extra_args + ["--no-color", "--no-ext-diff", "--", fname])

                if len(file_diff) <= DIFF_CHARS_PER_FILE:
                    content = file_diff
                else:
                    print(f"  Summarizing large diff: {fname} ({len(file_diff):,} chars)…",
                          file=sys.stderr)
                    content = self._summarize_file_diff(fname, file_diff)

                parts.append(content)
                total_chars += len(content)

                if total_chars >= DIFF_TOTAL_CHARS:
                    parts.append("\n... (remaining diffs omitted — total size limit reached)")
                    break
            else:
                continue
            break   # hit total limit inside inner loop

        untracked = self.git(["ls-files", "--others", "--exclude-standard"]).splitlines()
        if untracked:
            parts.append("Untracked (new files):\n" + "\n".join(f"  {f}" for f in untracked))

        return "\n".join(parts)

    def _read_file(self, path: str) -> str:
        """Read a repo file, rejecting path traversal and truncating large files."""
        target = (self.repo / path).resolve()
        if not str(target).startswith(str(self.repo) + os.sep) and target != self.repo:
            return f"[error: path traversal rejected for '{path}']"
        if not target.exists():
            return f"[file not found: {path}]"
        try:
            content = target.read_text(errors="replace")
        except OSError as e:
            return f"[error reading {path}: {e}]"
        if len(content) > READ_FILE_LIMIT:
            size = target.stat().st_size
            return (
                content[:READ_FILE_LIMIT]
                + f"\n\n[truncated — file is {size:,} bytes; showing first {READ_FILE_LIMIT:,} chars]"
            )
        return content

    def classify_changes(self, hunk_map: dict[str, DiffHunk], critique: str = "") -> tuple[list[dict], list[str]]:
        """Ask the model to group diff hunks into logical commits via an agentic loop.

        Returns (commits, gitignore_patterns).
        """
        hunk_context = self.build_hunk_context(hunk_map)

        critique_section = ""
        if critique:
            critique_section = (
                f"\n\nA reviewer rated the previous proposal below 7/10. Their feedback:\n"
                f"{critique}\n"
                f"Revise your commit groupings to address this feedback."
            )

        initial_message = hunk_context + critique_section

        tool_registry = {
            "read_file": read_file,
            "get_diff": get_diff,
            "get_git_log": get_git_log,
            "search_diff": search_diff,
        }

        return self.client.agentic_loop(
            system_prompt=AGENTIC_SYSTEM_PROMPT,
            initial_user_message=initial_message,
            tool_registry=tool_registry,
            terminal_tool=propose_commits,
            analyzer=self,
        )

    def merge_overlapping_commits(self, commits: list[dict]) -> list[dict]:
        """Merge commits that share hunk IDs (duplicate assignment is a model error).

        Different commits CAN touch different hunks of the same file — that is the
        whole point of hunk-level staging.  We only need to merge when the same
        hunk_id appears in more than one commit, since applying the same patch twice
        would fail.
        """
        if len(commits) <= 1:
            return commits

        # Build a mapping from each hunk_id to the commit indices that claim it
        hunk_to_indices: dict[str, list[int]] = {}
        for i, c in enumerate(commits):
            for h in c.get("hunks", []):
                hunk_to_indices.setdefault(h, []).append(i)

        # Union-find to group commits sharing a hunk
        parent = list(range(len(commits)))

        def find(x):
            while parent[x] != x:
                parent[x] = parent[parent[x]]
                x = parent[x]
            return x

        def union(a, b):
            ra, rb = find(a), find(b)
            if ra != rb:
                parent[rb] = ra

        for indices in hunk_to_indices.values():
            for idx in indices[1:]:
                union(indices[0], idx)

        # Group commits by their root
        groups: dict[int, list[int]] = {}
        for i in range(len(commits)):
            groups.setdefault(find(i), []).append(i)

        # If no merging needed, return as-is
        if all(len(idxs) == 1 for idxs in groups.values()):
            return commits

        merged = []
        for indices in groups.values():
            if len(indices) == 1:
                merged.append(commits[indices[0]])
                continue

            group = [commits[i] for i in indices]
            print(f"  Merging {len(group)} commits with duplicate hunks…", file=sys.stderr)

            all_hunks = list(dict.fromkeys(h for c in group for h in c.get("hunks", [])))
            all_issues = []
            seen_issues: set[tuple] = set()
            for c in group:
                for issue in c.get("issues", []):
                    key = (issue.get("path", ""), issue.get("message", ""))
                    if key not in seen_issues:
                        seen_issues.add(key)
                        all_issues.append(issue)

            commits_desc = json.dumps(group, indent=2)
            prompt = MERGE_PROMPT + commits_desc

            merged.append(self.client.call_with_tool(
                prompt, merge_commits,
                all_hunks=all_hunks, all_issues=all_issues,
            ))

        return merged

    def _build_combined_patch(self, hunks: list[str]) -> str:
        """Combine multiple hunks for the same file into a single valid patch.

        The first hunk's file header is kept; subsequent hunks contribute only
        their @@ sections onward, so git apply sees one coherent multi-hunk patch.
        """
        if len(hunks) == 1:
            return hunks[0]

        result: list[str] = []
        # Keep the full first hunk (file header + @@ lines)
        result.append(hunks[0])
        if not result[-1].endswith("\n"):
            result.append("\n")

        for hunk in hunks[1:]:
            # Skip file-header lines; start from the first @@ line
            in_hunk = False
            for line in hunk.splitlines(keepends=True):
                if line.startswith("@@"):
                    in_hunk = True
                if in_hunk:
                    result.append(line)
            if result and not result[-1].endswith("\n"):
                result.append("\n")

        return "".join(result)

    def execute_commits(self, commits: list[dict], hunk_map: dict[str, DiffHunk]) -> None:
        """Stage and commit each group using git apply --cached for individual hunks."""
        for i, commit in enumerate(commits, 1):
            subject = commit["subject"]
            body = commit.get("body", "").strip()
            breaking = commit.get("breaking_change", "").strip()
            parts = [subject]
            if body:
                parts.append(body)
            if breaking:
                parts.append(f"BREAKING CHANGE: {breaking}")
            message = "\n\n".join(parts)
            hunk_ids: list[str] = commit.get("hunks", [])

            print(f"\n[{i}/{len(commits)}] {subject}")

            # Group hunk IDs by file path (preserving order)
            by_file: dict[str, list[DiffHunk]] = {}
            untracked_paths: list[str] = []
            for hid in hunk_ids:
                dh = hunk_map.get(hid)
                if dh is None:
                    print(f"  ! Unknown hunk {hid!r}, skipping", file=sys.stderr)
                    continue
                if dh.is_untracked:
                    untracked_paths.append(dh.file_path)
                else:
                    by_file.setdefault(dh.file_path, []).append(dh)

            # Apply hunks per file via git apply --cached
            for fpath, file_hunks in by_file.items():
                patch_text = self._build_combined_patch([dh.patch for dh in file_hunks])
                with tempfile.NamedTemporaryFile(
                    mode="w", suffix=".patch", delete=False, encoding="utf-8"
                ) as f:
                    f.write(patch_text)
                    patch_file = f.name
                try:
                    self.git(["apply", "--cached", patch_file])
                    n = len(file_hunks)
                    print(f"  + {fpath} ({n} hunk{'s' if n != 1 else ''})")
                except RuntimeError as e:
                    print(f"  ! Could not apply patch for {fpath}: {e}", file=sys.stderr)
                finally:
                    os.unlink(patch_file)

            # Add untracked (new) files whole
            for fpath in untracked_paths:
                try:
                    self.git(["add", "--", fpath])
                    print(f"  + {fpath} (new file)")
                except RuntimeError as e:
                    print(f"  ! Could not add {fpath}: {e}", file=sys.stderr)

            # Check something is actually staged
            staged = self.git(["diff", "--cached", "--name-only"]).strip()
            if not staged:
                print("  (nothing staged, skipping)")
                continue

            try:
                self.git(["commit", "-m", message])
                print(f"  ✓ Committed")
            except RuntimeError as e:
                print(f"  ! Error committing: {e}", file=sys.stderr)
                raise

    def update_gitignore(self, patterns: list[str], yes: bool = False) -> None:
        """Offer to append suggested patterns to .gitignore, skipping any already present."""
        if not patterns:
            return

        gitignore_path = self.repo / ".gitignore"

        existing: set[str] = set()
        existing_content = ""
        if gitignore_path.exists():
            existing_content = gitignore_path.read_text()
            for line in existing_content.splitlines():
                stripped = line.strip()
                if stripped and not stripped.startswith("#"):
                    existing.add(stripped)

        new_patterns = [p for p in patterns if p not in existing]
        if not new_patterns:
            return

        print("\nSuggested .gitignore additions:")
        for p in new_patterns:
            print(f"  {p}")

        if not yes:
            try:
                answer = input("Add these to .gitignore? [y/N] ").strip().lower()
            except (KeyboardInterrupt, EOFError):
                return
            if answer not in ("y", "yes"):
                return

        with open(gitignore_path, "a") as f:
            if existing_content and not existing_content.endswith("\n"):
                f.write("\n")
            f.write("\n# Added by git-smart-commit\n")
            for p in new_patterns:
                f.write(f"{p}\n")

        print(f"  Updated .gitignore ({len(new_patterns)} new pattern(s)).")


# ── Display helpers ────────────────────────────────────────────────────────────

def print_proposed_commits(commits: list[dict], gitignore: list[str],
                           hunk_map: dict[str, "DiffHunk"] | None = None) -> None:
    print("\nProposed commits:")
    print("─" * 60)
    for i, commit in enumerate(commits, 1):
        print(f"\n  [{i}] {commit['subject']}")
        body = commit.get("body", "").strip()
        print()
        if body:
            for line in body.splitlines():
                print(f"      {line}")
        hunk_ids = commit.get("hunks", [])
        if hunk_ids:
            # Group by file for a cleaner display
            by_file: dict[str, list[str]] = {}
            for hid in hunk_ids:
                if hunk_map and hid in hunk_map:
                    fpath = hunk_map[hid].file_path
                else:
                    fpath = hid.rsplit("#", 1)[0] if "#" in hid else hid
                by_file.setdefault(fpath, []).append(hid)
            for fpath, hids in by_file.items():
                tags = ", ".join(hids)
                print(f"       + {fpath}  [{tags}]")
        breaking = commit.get("breaking_change", "").strip()
        if breaking:
            print(f"  ⚠ BREAKING CHANGE: {breaking}")
        if (issues := commit.get("issues")) != []:
            print("  Issues in this commit:")
            for issue in issues:
                print(f"    - {issue['path']}: {issue['message']}")
    if gitignore:
        print("\n  Suggested .gitignore patterns:")
        for pattern in gitignore:
            print(f"       {pattern}")
    print()


# ── Main ───────────────────────────────────────────────────────────────────────

def main() -> None:
    parser = argparse.ArgumentParser(
        description="Group git changes into logical commits using Qwen3-Coder.",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog=__doc__,
    )
    parser.add_argument("--repo", default=".", help="Path to git repository")
    parser.add_argument("--dry-run", action="store_true", help="Show proposed commits without executing")
    parser.add_argument("--model", default=None, help=f"Model name (default: {DEFAULT_MODEL}, or smart-commit.model in git config)")
    parser.add_argument("--yes", "-y", action="store_true", help="Commit without confirmation")
    parser.add_argument("--json", dest="json_out", action="store_true", help="Output JSON and exit")
    parser.add_argument(
        "--api-base", default=None,
        help="API base URL (default: http://localhost:11434 for Ollama). "
             "Use https://openrouter.ai/api/v1 for OpenRouter. "
             "Or set LLM_API_BASE env var.",
    )
    parser.add_argument(
        "--api-key", default=None,
        help="API key for authenticated endpoints (or set LLM_API_KEY env var)",
    )
    parser.add_argument(
        "--critique", default="",
        metavar="TEXT",
        help="Agent feedback on a previous proposal (triggers revised classification)",
    )
    parser.add_argument(
        "--plan", metavar="FILE",
        help="Execute a previously saved commit plan (JSON from --json / --save-plan). "
             "Skips classification entirely — the exact plan is replayed.",
    )
    parser.add_argument(
        "--save-plan", metavar="FILE",
        help="When used with --json, also write the plan to FILE for later use with --plan.",
    )
    parser.add_argument(
        "--setup", action="store_true",
        help="Run the interactive configuration wizard and exit.",
    )

    args = parser.parse_args()
    repo = Path(args.repo).resolve()

    # Setup wizard: run before git-repo validation so --setup --global works
    # from any directory (not just inside a git repo).
    if args.setup:
        # Try to resolve a repo for "local" scope option; silently ignore if
        # the current directory is not a git repo.
        setup_repo: Path | None = None
        check = subprocess.run(
            ["git", "rev-parse", "--git-dir"],
            cwd=repo,
            capture_output=True,
            text=True,
        )
        if check.returncode == 0:
            setup_repo = repo
        run_setup_wizard(setup_repo)
        return

    # Verify it's a git repo early so we can read git config
    try:
        _git(["rev-parse", "--git-dir"], repo)
    except RuntimeError:
        print(f"Error: {repo} is not a git repository.", file=sys.stderr)
        sys.exit(3)

    # Configure API backend.
    # Priority: CLI arg > env var > git config (smart-commit.*) > built-in default.
    gc = read_git_config(repo)
    api_config = ApiConfig(
        base_url=(
            args.api_base
            or os.environ.get("LLM_API_BASE")
            or gc.get("smart-commit.api-base")
            or OLLAMA_BASE_URL
        ).rstrip("/"),
        model=(
            args.model
            or os.environ.get("LLM_MODEL")
            or gc.get("smart-commit.model")
            or DEFAULT_MODEL
        ),
        api_key=(
            args.api_key
            or os.environ.get("LLM_API_KEY")
            or gc.get("smart-commit.api-key")
        ),
    )
    client = LLMClient(api_config)
    analyzer = GitAnalyzer(repo, client)

    # Collect hunks (unstages staged files first so everything is uniform)
    print("Scanning for changes...", file=sys.stderr)
    hunk_map = analyzer.collect_hunks()
    if not hunk_map:
        print("No changes found.", file=sys.stderr)
        sys.exit(1)

    # Plan replay mode: load a previously saved plan, skip classification
    if args.plan:
        try:
            with open(args.plan) as f:
                plan = json.load(f)
        except (OSError, json.JSONDecodeError) as e:
            print(f"Error: could not load plan from {args.plan}: {e}", file=sys.stderr)
            sys.exit(1)
        commits = plan["commits"]
        gitignore = plan.get("gitignore", [])
        # Restore saved patches into hunk_map if present (makes plan self-contained)
        for hunk_id, patch in plan.get("hunk_patches", {}).items():
            if hunk_id not in hunk_map:
                # Best-effort: reconstruct a DiffHunk from the saved patch
                fpath = hunk_id.rsplit("#", 1)[0] if "#" in hunk_id else hunk_id
                hunk_map[hunk_id] = DiffHunk(
                    hunk_id=hunk_id, file_path=fpath, patch=patch
                )
        print_proposed_commits(commits, gitignore, hunk_map)
        if not args.dry_run:
            if not args.yes:
                try:
                    answer = input("Proceed with these commits? [y/N] ").strip().lower()
                except (KeyboardInterrupt, EOFError):
                    return
                if answer not in ("y", "yes"):
                    print("Cancelled.")
                    return
            analyzer.execute_commits(commits, hunk_map)
            analyzer.update_gitignore(gitignore, yes=args.yes)
            print("\nDone.")
        return

    n_files = len({dh.file_path for dh in hunk_map.values()})
    n_hunks = len(hunk_map)
    print(f"Found {n_hunks} hunk(s) across {n_files} file(s). Analyzing...", file=sys.stderr)

    commits, gitignore = analyzer.classify_changes(hunk_map, critique=args.critique)

    usage = analyzer.client.usage
    if usage.total_tokens > 0:
        print(f"  {usage}", file=sys.stderr)

    # JSON mode: dump plan (including patches for self-contained replay) and exit
    if args.json_out:
        hunk_patches = {hid: dh.patch for hid, dh in hunk_map.items() if not dh.is_untracked}
        plan_json = json.dumps(
            {"commits": commits, "hunk_patches": hunk_patches, "gitignore": gitignore},
            indent=2,
        )
        print(plan_json)
        if args.save_plan:
            with open(args.save_plan, "w") as f:
                f.write(plan_json)
        return

    # Display proposed commits
    print_proposed_commits(commits, gitignore, hunk_map)

    if args.dry_run:
        return

    # Confirm unless --yes
    if not args.yes:
        try:
            answer = input("Proceed with these commits? [y/N] ").strip().lower()
        except (KeyboardInterrupt, EOFError):
            return
        if answer not in ("y", "yes"):
            print("Cancelled.")
            return

    analyzer.execute_commits(commits, hunk_map)
    analyzer.update_gitignore(gitignore, yes=args.yes)
    print("\nDone.")


if __name__ == "__main__":
    main()
